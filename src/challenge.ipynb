{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu soluci√≥n y todas las suposiciones que est√°s considerando. Aqu√≠ puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se detallar√° el c√≥mo se trabaj√≥ el archivo .json para cada una de las funciones. Tambien se considerar√°n todas las posibles mejoras necesarias al momento de trabajar los datos. El c√≥mo trabajar el archivo deber√≠a ser similar para cada caso, con algunos ejercicios requiriendo mas proceso que otros.\n",
    "\n",
    "Para el primer ejercicio se deberia priorizar un count por fecha en tweets, luego de cada fecha con count mas alto, hacer el count de los usuarios con mas publicaciones. Como solo se necesita la fecha y el autor, probablemente se pueda trabajar el archivo para reducir carga en busqueda por iteraci√≥n.\n",
    "\n",
    "Similar al anterior ejercicio, count por emoji que se encuentre, ordenar y retornar los 10 mas altos. En este caso solo se requiere el contenido del tweet y no los demas parametros. Transformar para el retorno el unicode en emoji.\n",
    "\n",
    "Nuevamente, contar los @usuarios que existan por post, ordenar y retornar los mas altos.\n",
    "\n",
    "Inicialmente para las soluciones mas rapidas, usaremos principalmente pandas para su manejo eficiente de columnas, dado que hay harto grouping que hacer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 2972.70 MiB, increment: -181.41 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "file_path = \"../../farmers-protest-tweets-2021-2-4.json\"\n",
    "data=[]\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        obj = json.loads(line)\n",
    "        data.append(obj)\n",
    "        \n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se agregan columnas a conveniencia, editando \"date\" para trabajarse con a√±o-mes-dia\n",
    "Adem√°s se agrega la columna username, que extrae el \"username\" del objeto \"user\" presente en cada fila.\n",
    "Se generan los dataframes, uno con los dias de mas tweets y otro con los usuarios que mas postearon en cada d√≠a, esto luego se mergea para tener el resultado final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most frequent username for each date:\n",
      "        date_only         username  count\n",
      "2740   2021-02-12  RanbirS00614606    176\n",
      "7536   2021-02-13  MaanDee08215437    178\n",
      "15136  2021-02-14    rebelpacifist    119\n",
      "18540  2021-02-15           jot__b    134\n",
      "23260  2021-02-16           jot__b    133\n",
      "26577  2021-02-17   RaaJVinderkaur    185\n",
      "33193  2021-02-18  neetuanjle_nitu    195\n",
      "35219  2021-02-19         Preetm91    267\n",
      "38382  2021-02-20  MangalJ23056160    108\n",
      "42691  2021-02-21       Surrypuria    161\n",
      "46533  2021-02-22   preetysaini321    110\n",
      "48696  2021-02-23       Surrypuria    135\n",
      "51458  2021-02-24   preetysaini321    107\n",
      "13\n",
      "13\n",
      "peak memory: 2905.12 MiB, increment: -304.83 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['date_only'] = df['date'].dt.date\n",
    "df['username'] = df['user'].apply(lambda x: x['username'])\n",
    "\n",
    "grouped = df.groupby(['date_only', 'username']).size().reset_index(name='count')\n",
    "most_frequent_user = grouped.loc[grouped.groupby('date_only')['count'].idxmax()]\n",
    "print(\"\\nMost frequent username for each date:\")\n",
    "print(most_frequent_user)\n",
    "\n",
    "grouped_df=df.groupby('date_only').size().reset_index(name='count')\n",
    "\n",
    "print(len(most_frequent_user))\n",
    "print(len(grouped_df))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     date_only         username  count_x  count_y\n",
      "0   2021-02-12  RanbirS00614606      176    12347\n",
      "1   2021-02-13  MaanDee08215437      178    11296\n",
      "5   2021-02-17   RaaJVinderkaur      185    11087\n",
      "4   2021-02-16           jot__b      133    10443\n",
      "2   2021-02-14    rebelpacifist      119    10249\n",
      "6   2021-02-18  neetuanjle_nitu      195     9625\n",
      "3   2021-02-15           jot__b      134     9197\n",
      "8   2021-02-20  MangalJ23056160      108     8502\n",
      "11  2021-02-23       Surrypuria      135     8417\n",
      "7   2021-02-19         Preetm91      267     8204\n",
      "9   2021-02-21       Surrypuria      161     7532\n",
      "10  2021-02-22   preetysaini321      110     7071\n",
      "12  2021-02-24   preetysaini321      107     3437\n",
      "peak memory: 3037.06 MiB, increment: -68.02 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "join=pd.merge(most_frequent_user,grouped_df, on='date_only')\n",
    "sorted_join = join.sort_values(by='count_y', ascending=False)\n",
    "\n",
    "print(sorted_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora con este dataframe solo falta tomar los 10 primeros, pasarlos a una lista de tuplas para el retorno de q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n",
      "peak memory: 3128.62 MiB, increment: -213.75 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "dateuser=sorted_join[['date_only','username']].head(10)\n",
    "q1_t = [tuple(x) for x in dateuser.values]\n",
    "print(q1_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2 Es un problema mucho mas simple, utilizando la libreria emoji y counter se resuelve rapidamente, siendo eficiente, dentro de lo posible, en el uso de memoria y tiempo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('üôè', 7286), ('üòÇ', 3072), ('üöú', 2972), ('‚úä', 2411), ('üåæ', 2363), ('üèª', 2080), ('‚ù§', 1779), ('ü§£', 1668), ('üèΩ', 1218), ('üëá', 1108)]\n",
      "peak memory: 2815.64 MiB, increment: -123.66 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "import emoji\n",
    "from collections import Counter\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    emoji_counts = Counter()\n",
    "    for line in file:\n",
    "        obj = json.loads(line)\n",
    "        for char in obj[\"content\"]:\n",
    "            if char in emoji.EMOJI_DATA:\n",
    "                emoji_counts[char] += 1\n",
    "\n",
    "emoji_counts=sorted(emoji_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "print(emoji_counts)\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3 Es similar a Q2, con la diferencia que esta vez se utilizan expresiones regulares para detectar las menciones en usuarios en el contenido de cada tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('narendramodi', 2261), ('Kisanektamorcha', 1836), ('RakeshTikaitBKU', 1639), ('PMOIndia', 1422), ('RahulGandhi', 1125), ('GretaThunberg', 1046), ('RaviSinghKA', 1015), ('rihanna', 972), ('UNHumanRights', 962), ('meenaharris', 925)]\n",
      "peak memory: 2840.08 MiB, increment: -246.41 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "import re\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    dif_mentions = Counter()\n",
    "    mention = re.compile(r'@(\\w+)')\n",
    "\n",
    "    for line in file:\n",
    "        obj = json.loads(line)\n",
    "        mentions = mention.findall(obj[\"content\"])\n",
    "        dif_mentions.update(mentions)\n",
    "print (dif_mentions.most_common(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto Q2 como Q3 son problemas simples que no tienen variaci√≥n en caso de generar soluciones distintas para mejor tiempo o mejor memoria. Por otra parte Q1 si es trabajable, dado que todo el grouping y el uso de dataframes puede ser reducido a costa de hacer mas iteraciones pero ocupando menos memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hara una implementacion de Q1 sin pandas, buscando realizar las operaciones lo mas inplace posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('2021-02-12', 12347), ('2021-02-13', 11296), ('2021-02-17', 11087), ('2021-02-16', 10443), ('2021-02-14', 10249), ('2021-02-18', 9625), ('2021-02-15', 9197), ('2021-02-20', 8502), ('2021-02-23', 8417), ('2021-02-19', 8204)]\n",
      "peak memory: 2298.62 MiB, increment: -152.70 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "file_path = \"../../farmers-protest-tweets-2021-2-4.json\"\n",
    "from datetime import datetime, date\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    date_count=Counter()\n",
    "    for line in file:\n",
    "        obj = json.loads(line)\n",
    "        dt = datetime.fromisoformat(obj['date'])\n",
    "        date = dt.strftime('%Y-%m-%d')\n",
    "        date_count[date]+=1\n",
    "    top_dates=date_count.most_common(10)\n",
    "\n",
    "print(top_dates)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'rebelpacifist'), (datetime.date(2021, 2, 18), 'neetuanjle_nitu'), (datetime.date(2021, 2, 15), 'jot__b'), (datetime.date(2021, 2, 20), 'MangalJ23056160'), (datetime.date(2021, 2, 23), 'Surrypuria'), (datetime.date(2021, 2, 19), 'Preetm91')]\n",
      "peak memory: 1809.86 MiB, increment: -297.02 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "\n",
    "date_user=[]\n",
    "for dates in top_dates:\n",
    "        user_count=Counter()\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                obj = json.loads(line)\n",
    "                dt = datetime.fromisoformat(obj['date'])\n",
    "                date = dt.strftime('%Y-%m-%d')\n",
    "                if date==dates[0]:\n",
    "                    user = obj['user']['username']\n",
    "                    user_count[user]+=1\n",
    "            dt = datetime.strptime(dates[0], '%Y-%m-%d')\n",
    "            date_obj = dt.date()\n",
    "            date_user.append((date_obj,user_count.most_common(1)[0][0]))\n",
    "print(date_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que el PEAK de memoria utilizada fueron 2298.62 MiB mientras que el codigo utilizando pandas ocup√≥ 3128.62 MiB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejora de espacio:  36.118363794604 % menos espacio\n",
      "Empeoramiento en tiempo:  115.4471544715447 % mas lento\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejora de espacio: \", ((3128/2298)-1)*100, \"% menos espacio\")\n",
    "print(\"Empeoramiento en tiempo: \", (((23.6+2.9)/(10.4+0.4+1.1+0.4))-1)*100, \"% mas lento\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que se puede obtener mejor uso de memoria pero a un alto costo en tiempo, dado que pandas vectoriza y realiza operaciones en columnas de forma mucho mas optima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, en caso de trabajar con archivos considerablemente mas grandes, seria oportuno ocupar soluciones cloud como Dataflow, por ejemplo para Q1 *personalmente* utilizar√≠a la soluci√≥n con pandas como script."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
